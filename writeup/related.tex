\subsection{Related Work}
Waiting for Dan to show me how to make proper references

....

More to come

\vspace{10mm}

%The idea of Posterior or Thompson sampling is not new in the literature [Thompson]. However, in the context of MAB or 
%reinforcement learning it has received substantially less attention than OFU techniques [Lai].
%
%Empirically, posterior sampling has been shown to work as well or better than state of the art techniques [Chapelle] and it is
%implemented in industry, notably by Microsoft Bing. Recently there have been successful analyses of the MAB problem in the
%case of posterior sampling [Russo][Kauffman][May] which have shown optimal regret bounds for the algorithm.
%
%As far as the tabula rasa reinforcement learning problem, there have been elements of bayesian sampling incorporated into successful
%algorithms [BOSS] however the state of the art algorithms employ OFU principles [UCRL2][REGAL].
%
%We present theoretical analysis which gives, for problems of bounded span, matching Bayesian Regret bounds with a simpler
%algorithm. For the general case, we obtain polynomial learning rates but with worst case performance below [UCRL2][REGAL].
%In practice, we suspect that performance may remain competitive... but we're not sure.
